"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[774],{6491:(e,t,a)=>{a.d(t,{LanguageProvider:()=>n,o:()=>c});var s=a(8081),o=a(2149);let r=(0,o.createContext)(void 0),i={ko:{"nav.home":"홈","nav.research":"연구","nav.team":"팀","nav.publications":"논문","nav.news":"소식","nav.contact":"연락","nav.theme":"테마","nav.language":"언어","nav.forceToggle":"강제 토글","home.hero.badge":"Advancing AI Research","home.hero.title":"Large Language Models &","home.hero.titleHighlight":" Mixture of Experts","home.hero.description":"우리 연구실은 대규모 언어 모델과 전문가 혼합 모델을 통해 차세대 AI 시스템을 개발하고 있습니다. 효율적이고 확장 가능한 AI 아키텍처 연구에 집중합니다.","home.hero.researchBtn":"Research Overview","home.hero.joinBtn":"Join Our Team","home.hero.currentFocus":"Current Focus","home.hero.efficientLLM":"Efficient LLM Training","home.hero.moeArch":"MoE Architecture","home.research.title":"Research Areas","home.research.subtitle":"우리의 주요 연구 분야와 혁신적인 접근 방식을 소개합니다","home.research.llm.title":"Large Language Models","home.research.llm.desc":"대규모 언어 모델의 효율적인 학습과 추론 방법론 연구","home.research.moe.title":"Mixture of Experts","home.research.moe.desc":"전문가 혼합 모델을 통한 확장 가능한 AI 아키텍처 개발","home.research.efficient.title":"Efficient AI Systems","home.research.efficient.desc":"에너지 효율적이고 지속 가능한 AI 시스템 구축","home.research.viewAll":"View All Research","home.team.title":"Our Team","home.team.subtitle":"세계적 수준의 연구진과 함께 AI의 미래를 만들어갑니다","home.team.pi":"Principal Investigator","home.team.professor":"김AI 교수","home.team.professorTitle":"Professor of Computer Science","home.team.professorDesc":"Stanford University Ph.D., 15년간 AI 연구 경력, Nature, Science 등 최고 저널 100편 이상 논문 발표","home.team.meetTeam":"Meet Our Team","home.publications.title":"Recent Publications","home.publications.subtitle":"최신 연구 성과와 논문을 확인하세요","home.publications.viewAll":"View All Publications","home.news.title":"News & Updates","home.news.subtitle":"연구실의 최신 소식과 업데이트를 확인하세요","home.news.viewAll":"View All News","home.contact.title":"Contact Us","home.contact.subtitle":"연구 협력이나 입학 문의는 언제든 연락주세요","home.contact.info":"연구실 정보","home.contact.address":"주소","home.contact.email":"이메일","home.contact.admission":"입학 및 연구 참여","home.contact.admissionDesc":"우리 연구실에서는 열정적인 연구자를 찾고 있습니다. LLM, MoE, 또는 AI 시스템에 관심이 있으시면 언제든 연락주세요.","home.contact.fields":"모집 분야:","home.contact.inquiry":"문의하기","footer.description":"차세대 AI 기술을 통해 인류의 미래를 만들어갑니다.","footer.quickLinks":"Quick Links","footer.connect":"Connect","footer.copyright":"\xa9 2024 AI Research Lab. All rights reserved.","research.title":"Research Areas","research.subtitle":"우리 연구실은 대규모 언어 모델과 전문가 혼합 모델을 통해 차세대 AI 시스템을 개발하고 있습니다","research.llm.title":"Large Language Models","research.llm.description":"대규모 언어 모델(LLM)은 자연어 처리의 혁명을 가져왔습니다. 우리 연구실은 LLM의 효율성, 정확성, 그리고 응용 가능성을 높이기 위한 다양한 연구를 진행하고 있습니다.","research.llm.focus":"특히 모델 압축, 효율적인 파인튜닝, 다중 모달 통합, 그리고 맥락 학습 능력 향상에 초점을 맞추고 있습니다.","research.moe.title":"Mixture of Experts","research.moe.description":"전문가 혼합 모델(MoE)은 대규모 AI 모델의 효율성과 확장성을 크게 향상시킬 수 있는 혁신적인 아키텍처입니다. 우리 연구실은 MoE 모델의 설계, 학습, 그리고 배포에 관한 최첨단 연구를 수행하고 있습니다.","research.moe.focus":"특히 희소 MoE 아키텍처, 전문가 라우팅 알고리즘, 부하 균형 전략, 그리고 분산 학습에 초점을 맞추고 있습니다.","research.systems.title":"Efficient AI Systems","research.systems.description":"AI 시스템의 에너지 효율성과 지속 가능성은 현대 AI 연구의 중요한 과제입니다. 우리 연구실은 환경 친화적이고 자원 효율적인 AI 시스템 개발에 주력하고 있습니다.","research.systems.focus":"특히 그린 AI 컴퓨팅, 엣지 AI 배포, 연합 학습, 그리고 하드웨어-소프트웨어 공동 설계에 초점을 맞추고 있습니다.","research.projects.title":"Current Projects","research.status.ongoing":"진행 중","research.status.planned":"계획 중","team.title":"Our Team","team.subtitle":"세계적 수준의 연구진과 함께 AI의 미래를 만들어갑니다","team.faculty":"Faculty","team.researchers":"Researchers","team.students":"Students","team.biography":"Biography","team.interests":"Research Interests","team.education":"Education","team.awards":"Awards & Honors","team.focus":"Focus Area","team.bio":"Bio","team.thesis":"Thesis Topic","team.advisor":"Advisor","publications.title":"Publications","publications.subtitle":"우리 연구실의 최신 연구 성과와 논문을 확인하세요","publications.search":"논문 제목, 저자, 키워드로 검색...","publications.year":"연도","publications.allYears":"모든 연도","publications.category":"분야","publications.allCategories":"모든 분야","publications.results":"개의 논문이 검색되었습니다.","publications.total":"총","publications.citations":"인용","publications.times":"회","publications.abstract":"Abstract","publications.noResults":"검색 결과가 없습니다","publications.tryOther":"다른 검색어나 필터를 시도해보세요.","news.title":"News & Updates","news.subtitle":"연구실의 최신 소식과 업데이트를 확인하세요","news.latest":"최신 소식","news.all":"모든 소식","news.readMore":"자세히 보기","news.viewMore":"더 많은 소식 보기","contact.title":"Contact Us","contact.subtitle":"연구 협력이나 입학 문의는 언제든 연락주세요","contact.labInfo":"연구실 정보","contact.address":"주소","contact.email":"이메일","contact.phone":"전화번호","contact.hours":"운영 시간","contact.directions":"찾아오는 길","contact.subway":"지하철","contact.bus":"버스","contact.parking":"자가용","contact.inquiry":"문의하기","contact.inquiryDesc":"연구 협력, 입학 문의, 기타 궁금한 사항이 있으시면 아래 양식을 작성해 주세요.","contact.name":"이름","contact.subject":"제목","contact.category":"문의 유형","contact.selectCategory":"문의 유형을 선택해주세요","contact.admission":"입학 문의","contact.research":"연구 협력","contact.internship":"인턴십","contact.visit":"연구실 방문","contact.other":"기타","contact.message":"메시지","contact.send":"문의 보내기","contact.admissionGuide":"입학 및 연구 참여 안내","contact.admissionDesc":"우리 연구실에서는 열정적인 연구자를 찾고 있습니다. LLM, MoE, 또는 AI 시스템에 관심이 있으시면 언제든 연락주세요.","contact.recruitmentAreas":"모집 분야","contact.qualifications":"지원 자격","contact.documents":"제출 서류"},en:{"nav.home":"Home","nav.research":"Research","nav.team":"Team","nav.publications":"Publications","nav.news":"News","nav.contact":"Contact","nav.theme":"Theme","nav.language":"Language","nav.forceToggle":"Force Toggle","home.hero.badge":"Advancing AI Research","home.hero.title":"Large Language Models &","home.hero.titleHighlight":" Mixture of Experts","home.hero.description":"Our research lab develops next-generation AI systems through large language models and mixture of experts models. We focus on efficient and scalable AI architecture research.","home.hero.researchBtn":"Research Overview","home.hero.joinBtn":"Join Our Team","home.hero.currentFocus":"Current Focus","home.hero.efficientLLM":"Efficient LLM Training","home.hero.moeArch":"MoE Architecture","home.research.title":"Research Areas","home.research.subtitle":"Introducing our key research areas and innovative approaches","home.research.llm.title":"Large Language Models","home.research.llm.desc":"Research on efficient training and inference methodologies for large language models","home.research.moe.title":"Mixture of Experts","home.research.moe.desc":"Development of scalable AI architectures through mixture of experts models","home.research.efficient.title":"Efficient AI Systems","home.research.efficient.desc":"Building energy-efficient and sustainable AI systems","home.research.viewAll":"View All Research","home.team.title":"Our Team","home.team.subtitle":"Creating the future of AI with world-class researchers","home.team.pi":"Principal Investigator","home.team.professor":"Prof. AI Kim","home.team.professorTitle":"Professor of Computer Science","home.team.professorDesc":"Stanford University Ph.D., 15 years of AI research experience, published over 100 papers in top journals including Nature and Science","home.team.meetTeam":"Meet Our Team","home.publications.title":"Recent Publications","home.publications.subtitle":"Check out our latest research achievements and papers","home.publications.viewAll":"View All Publications","home.news.title":"News & Updates","home.news.subtitle":"Stay updated with our latest news and announcements","home.news.viewAll":"View All News","home.contact.title":"Contact Us","home.contact.subtitle":"Feel free to contact us for research collaboration or admission inquiries","home.contact.info":"Lab Information","home.contact.address":"Address","home.contact.email":"Email","home.contact.admission":"Admission & Research Participation","home.contact.admissionDesc":"We are looking for passionate researchers. If you are interested in LLM, MoE, or AI systems, please feel free to contact us.","home.contact.fields":"Recruitment Areas:","home.contact.inquiry":"Contact Us","footer.description":"Creating the future of humanity through next-generation AI technology.","footer.quickLinks":"Quick Links","footer.connect":"Connect","footer.copyright":"\xa9 2024 AI Research Lab. All rights reserved.","research.title":"Research Areas","research.subtitle":"Our research lab develops next-generation AI systems through large language models and mixture of experts models","research.llm.title":"Large Language Models","research.llm.description":"Large Language Models (LLMs) have revolutionized natural language processing. Our lab conducts various research to improve the efficiency, accuracy, and applicability of LLMs.","research.llm.focus":"We particularly focus on model compression, efficient fine-tuning, multi-modal integration, and improving in-context learning capabilities.","research.moe.title":"Mixture of Experts","research.moe.description":"Mixture of Experts (MoE) is an innovative architecture that can significantly improve the efficiency and scalability of large AI models. Our lab conducts cutting-edge research on the design, training, and deployment of MoE models.","research.moe.focus":"We particularly focus on sparse MoE architectures, expert routing algorithms, load balancing strategies, and distributed training.","research.systems.title":"Efficient AI Systems","research.systems.description":"Energy efficiency and sustainability of AI systems are important challenges in modern AI research. Our lab focuses on developing environmentally friendly and resource-efficient AI systems.","research.systems.focus":"We particularly focus on green AI computing, edge AI deployment, federated learning, and hardware-software co-design.","research.projects.title":"Current Projects","research.status.ongoing":"Ongoing","research.status.planned":"Planned","team.title":"Our Team","team.subtitle":"Creating the future of AI with world-class researchers","team.faculty":"Faculty","team.researchers":"Researchers","team.students":"Students","team.biography":"Biography","team.interests":"Research Interests","team.education":"Education","team.awards":"Awards & Honors","team.focus":"Focus Area","team.bio":"Bio","team.thesis":"Thesis Topic","team.advisor":"Advisor","publications.title":"Publications","publications.subtitle":"Check out our latest research achievements and papers","publications.search":"Search by paper title, author, keywords...","publications.year":"Year","publications.allYears":"All Years","publications.category":"Category","publications.allCategories":"All Categories","publications.results":"papers found.","publications.total":"Total","publications.citations":"Citations","publications.times":"times","publications.abstract":"Abstract","publications.noResults":"No search results found","publications.tryOther":"Try different keywords or filters.","news.title":"News & Updates","news.subtitle":"Stay updated with our latest news and announcements","news.latest":"Latest News","news.all":"All News","news.readMore":"Read More","news.viewMore":"View More News","contact.title":"Contact Us","contact.subtitle":"Feel free to contact us for research collaboration or admission inquiries","contact.labInfo":"Lab Information","contact.address":"Address","contact.email":"Email","contact.phone":"Phone","contact.hours":"Office Hours","contact.directions":"Directions","contact.subway":"Subway","contact.bus":"Bus","contact.parking":"Parking","contact.inquiry":"Contact Form","contact.inquiryDesc":"Please fill out the form below for research collaboration, admission inquiries, or other questions.","contact.name":"Name","contact.subject":"Subject","contact.category":"Inquiry Type","contact.selectCategory":"Please select inquiry type","contact.admission":"Admission Inquiry","contact.research":"Research Collaboration","contact.internship":"Internship","contact.visit":"Lab Visit","contact.other":"Other","contact.message":"Message","contact.send":"Send Inquiry","contact.admissionGuide":"Admission & Research Participation Guide","contact.admissionDesc":"We are looking for passionate researchers. If you are interested in LLM, MoE, or AI systems, please feel free to contact us.","contact.recruitmentAreas":"Recruitment Areas","contact.qualifications":"Qualifications","contact.documents":"Required Documents"}};function n(e){let{children:t}=e,[a,n]=(0,o.useState)("ko"),[c,l]=(0,o.useState)(!1);return(0,o.useEffect)(()=>{let e=localStorage.getItem("language");e&&("ko"===e||"en"===e)&&n(e),l(!0)},[]),(0,s.jsx)(r.Provider,{value:{language:a,setLanguage:e=>{console.log("Setting language to:",e),n(e),localStorage.setItem("language",e)},t:e=>{let t=i[a];return t&&t[e]?t[e]:e}},children:t})}function c(){let e=(0,o.useContext)(r);if(void 0===e)throw Error("useLanguage must be used within a LanguageProvider");return e}},6810:(e,t,a)=>{a.d(t,{BT:()=>l,Wu:()=>u,ZB:()=>c,Zp:()=>i,aR:()=>n});var s=a(8081),o=a(2149),r=a(7687);let i=o.forwardRef((e,t)=>{let{className:a,...o}=e;return(0,s.jsx)("div",{ref:t,className:(0,r.cn)("rounded-lg border bg-card text-card-foreground shadow-sm",a),...o})});i.displayName="Card";let n=o.forwardRef((e,t)=>{let{className:a,...o}=e;return(0,s.jsx)("div",{ref:t,className:(0,r.cn)("flex flex-col space-y-1.5 p-6",a),...o})});n.displayName="CardHeader";let c=o.forwardRef((e,t)=>{let{className:a,...o}=e;return(0,s.jsx)("div",{ref:t,className:(0,r.cn)("text-2xl font-semibold leading-none tracking-tight",a),...o})});c.displayName="CardTitle";let l=o.forwardRef((e,t)=>{let{className:a,...o}=e;return(0,s.jsx)("div",{ref:t,className:(0,r.cn)("text-sm text-muted-foreground",a),...o})});l.displayName="CardDescription";let u=o.forwardRef((e,t)=>{let{className:a,...o}=e;return(0,s.jsx)("div",{ref:t,className:(0,r.cn)("p-6 pt-0",a),...o})});u.displayName="CardContent",o.forwardRef((e,t)=>{let{className:a,...o}=e;return(0,s.jsx)("div",{ref:t,className:(0,r.cn)("flex items-center p-6 pt-0",a),...o})}).displayName="CardFooter"},7687:(e,t,a)=>{a.d(t,{cn:()=>r});var s=a(6522),o=a(4483);function r(){for(var e=arguments.length,t=Array(e),a=0;a<e;a++)t[a]=arguments[a];return(0,o.QP)((0,s.$)(t))}}}]);